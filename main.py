# -*- coding: utf-8 -*-
"""main.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1-3ikgqV9FwPfSvHJ-CJYtp_To0eRY47-
"""

from fastapi import FastAPI, HTTPException
from data_loader import fetch_messages
from prompt_builder import build_prompt
from openai_client import ask_llm

app = FastAPI(title="LLM QA System - GPT-4.x")

@app.get("/ask")
async def ask(question: str):
    try:
        messages = fetch_messages()
        prompt = build_prompt(question, messages)
        answer = ask_llm(prompt)
        return {"answer": answer}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))